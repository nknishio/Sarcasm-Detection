{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL ARCHITECTURE FROM\n",
        "https://arxiv.org/pdf/2406.00367\n",
        "\n",
        "Changes: Changed from BiLSTM classification to CNN"
      ],
      "metadata": {
        "id": "sf67BBsJX7jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#download dataset to local/virtual environment and set up python libraries\n",
        "\n",
        "# !gdown \"https://drive.google.com/uc?id=1YeV-FnAWkPQkpTPgf-ShXhb3SbTb65RP\"\n",
        "# !gdown 'https://drive.google.com/uc?export=download&id=1w9h_rF7-ziI-rqiXTi0SnWEV9nkpDQlh' -O config.json\n",
        "!pip install torch transformers pandas numpy scikit-learn nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X3h7VXVGXnJ",
        "outputId": "59eb3012-dbde-4d67-9b2d-3dfba7de08bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in ./myenv/lib/python3.12/site-packages (2.6.0)\r\n",
            "Requirement already satisfied: transformers in ./myenv/lib/python3.12/site-packages (4.51.0)\r\n",
            "Requirement already satisfied: pandas in ./myenv/lib/python3.12/site-packages (2.2.3)\r\n",
            "Requirement already satisfied: numpy in ./myenv/lib/python3.12/site-packages (2.2.4)\r\n",
            "Requirement already satisfied: scikit-learn in ./myenv/lib/python3.12/site-packages (1.6.1)\r\n",
            "Requirement already satisfied: nltk in ./myenv/lib/python3.12/site-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in ./myenv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./myenv/lib/python3.12/site-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in ./myenv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./myenv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./myenv/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./myenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./myenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./myenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./myenv/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./myenv/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./myenv/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./myenv/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./myenv/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./myenv/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./myenv/lib/python3.12/site-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./myenv/lib/python3.12/site-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./myenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./myenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in ./myenv/lib/python3.12/site-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: setuptools in ./myenv/lib/python3.12/site-packages (from torch) (78.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./myenv/lib/python3.12/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./myenv/lib/python3.12/site-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.12/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./myenv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in ./myenv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./myenv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./myenv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./myenv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./myenv/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./myenv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./myenv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in ./myenv/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGqJIRVMANGX"
      },
      "source": [
        "# Mount Google Drive and load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "uhqEnHFvALHL",
        "outputId": "79c76051-a158-433c-a5e9-ccddc4765a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 28619\n",
            "is_sarcastic\n",
            "0    14985\n",
            "1    13634\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/user96/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/user96/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   is_sarcastic                                           headline  \\\n",
              "0             1  thirtysomething scientists unveil doomsday clo...   \n",
              "1             0  dem rep. totally nails why congress is falling...   \n",
              "2             0  eat your veggies: 9 deliciously different recipes   \n",
              "3             1  inclement weather prevents liar from getting t...   \n",
              "4             1  mother comes pretty close to using word 'strea...   \n",
              "\n",
              "                                        article_link  \n",
              "0  https://www.theonion.com/thirtysomething-scien...  \n",
              "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
              "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
              "3  https://local.theonion.com/inclement-weather-p...  \n",
              "4  https://www.theonion.com/mother-comes-pretty-c...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#for nonlocal runtime\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# import pandas as pd\n",
        "# df = pd.read_csv(\"/content/drive/My Drive/Kaggle Club/SARCASM PROJECT '25/cleaned_reddit_comments.csv\").fillna(' ')\n",
        "\n",
        "# Load the CSV dataset (adjust the file path as needed)\n",
        "df = pd.read_csv('cleaned_NewsHeadlines_comments.csv', usecols=['is_sarcastic', 'headline']).fillna('')\n",
        "df = pd.read_json(\"config.json\", lines = True).fillna('')\n",
        "\n",
        "print(\"Dataset size:\", len(df))\n",
        "print(df['is_sarcastic'].value_counts())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, split into (train+validation) vs. test (90% vs. 10%)\n",
        "train_val_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.10,\n",
        "    random_state=42,\n",
        "    stratify=df['is_sarcastic']\n",
        ")\n",
        "\n",
        "# Now split the train_val_df into training and validation sets (90% of 90% becomes 81%, and 10% of 90% becomes 9%)\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df,\n",
        "    test_size=0.10,\n",
        "    random_state=42,\n",
        "    stratify=train_val_df['is_sarcastic']\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Validation size:\", len(val_df))\n",
        "print(\"Test size:\", len(test_df))"
      ],
      "metadata": {
        "id": "CM-TjKVcYmqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9dfe332-fd55-4258-cc51-bfbdd58e6198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 23181\n",
            "Validation size: 2576\n",
            "Test size: 2862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Architecture\n",
        "\n",
        "\n",
        "1. RoBERTa Encoder:\n",
        "* Load a pretrained RoBERTa (roberta-base) model and its tokenizer from the HuggingFace library.\n",
        "* Use RoBERTa to obtain the embedding matrix for the input text.\n",
        "2. Dropout Layer:\n",
        "* Applied to the embeddings to prevent overfitting. In the paper, a dropout rate of 0.1 is used.\n",
        "3. ~~BiLSTM~~ CNN Layer:\n",
        "* Processes the embeddings bidirectionally to capture long-range dependencies.\n",
        "* The paper experiments with different hidden unit sizes (e.g., 128, 256, 512). For the CNN, the effective hidden size is doubled due to its forward and backward processing.\n",
        "4. Flatten and Dense Layers:\n",
        "* The output of the CNN is flattened.\n",
        "* One or two fully connected layers are used to capture the relationship between the features and the final sentiment classes.\n",
        "5. Classification (Softmax) Layer:\n",
        "* A Softmax function is applied to output the probability distribution over sentiment classes (e.g., positive, negative, neutral)."
      ],
      "metadata": {
        "id": "L32xLiLRW_Xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import RobertaModel, RobertaTokenizer, get_linear_schedule_with_warmup\n",
        "\n",
        "class RoBERTaCNN(nn.Module):\n",
        "    def __init__(self, roberta, num_filters, filter_sizes, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.roberta = roberta\n",
        "        hidden_size = roberta.config.hidden_size\n",
        "\n",
        "        # Convs for each kernel size + BatchNorm\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv1d(hidden_size, num_filters, fs),\n",
        "                nn.BatchNorm1d(num_filters),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "            for fs in filter_sizes\n",
        "        ])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # single logit\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # RoBERTa embeddings\n",
        "        seq_out = self.roberta(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "        x = seq_out.transpose(1, 2)   # (B, hidden, L)\n",
        "\n",
        "        # conv → pool\n",
        "        feats = []\n",
        "        for conv in self.convs:\n",
        "            c = conv(x)                # (B, F, L_out)\n",
        "            p = F.max_pool1d(c, c.size(2)).squeeze(2)\n",
        "            feats.append(p)\n",
        "        x = torch.cat(feats, dim=1)    # (B, F * #sizes)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc(x).squeeze(-1) # (B,)\n",
        "        return logits\n",
        "\n",
        "    def tokenize(self, texts, max_length=128):\n",
        "        enc = self.tokenizer(texts,\n",
        "                             padding=True,\n",
        "                             truncation=True,\n",
        "                             max_length=max_length,\n",
        "                             return_tensors='pt')\n",
        "        return enc.input_ids, enc.attention_mask\n",
        "\n",
        "# example instantiation\n",
        "if __name__ == \"__main__\":\n",
        "    model_name = \"roberta-base\"\n",
        "    roberta = RobertaModel.from_pretrained(model_name)\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    model = RoBERTaCNN(roberta, num_filters=100, filter_sizes=[2,3,4], dropout=0.1)\n",
        "    model.tokenizer = tokenizer  # attach tokenizer for convenience\n",
        "\n",
        "    texts = [\"I loved this movie\", \"Totally awful experience\"]\n",
        "    ids, mask = model.tokenize(texts)\n",
        "    logits = model(ids, mask)\n",
        "    probs = torch.sigmoid(logits)\n",
        "    print(\"Logits:\", logits)\n",
        "    print(\"Probabilities:\", probs)"
      ],
      "metadata": {
        "id": "f-1YW_JZW_Fy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d41076-f779-4850-ee7b-39b2df0af7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: tensor([ 0.1258, -0.9527], grad_fn=<SqueezeBackward1>)\n",
            "Probabilities: tensor([0.5314, 0.2783], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek4Hc9tdAPpf"
      },
      "source": [
        "# Training + Hyperparameters\n",
        "\n",
        "* **Learning Rates (l)**: Experiment with l ∈ {0.0001, 0.00001, 0.000001}. In the best-case experimental settings (as per the paper), use 0.00001.\n",
        "* **Hidden Units (h)**: For the RNN layer, experiment with 128, 256, or 512 units. ~~Note that for BiLSTM, the effective output dimension is 2×h.~~\n",
        "* **Dropout Rate**: 0.1\n",
        "* **Epochs**: ~~5 (as stated in the paper)~~ used early stopping w/ patience level of 5\n",
        "* **Optimizer**: AdamW is recommended."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 20\n",
        "\n",
        "class NewsHeadlinesDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        # Store the preprocessed texts and labels\n",
        "        self.labels = df['is_sarcastic'].values\n",
        "        self.comments = df['headline'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return the comment and label for a given index\n",
        "        comment = str(self.comments[idx])\n",
        "        label = self.labels[idx]\n",
        "        return comment, label\n",
        "\n",
        "# Create dataset objects\n",
        "train_dataset = NewsHeadlinesDataset(train_df)\n",
        "val_dataset = NewsHeadlinesDataset(val_df)\n",
        "test_dataset = NewsHeadlinesDataset(test_df)\n",
        "\n",
        "# Create DataLoaders for batching (adjust batch_size as needed)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "dultTdWJYvOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Training Loop (binary) =====\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer + scheduler\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-6, weight_decay=0.01)\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=int(0.1*total_steps),\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "best_val = float('inf')\n",
        "patience = 5\n",
        "stalled = 0\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for texts, labels in train_loader:\n",
        "        ids, mask = model.tokenize(list(texts))\n",
        "        ids, mask = ids.to(device), mask.to(device)\n",
        "        labels = torch.tensor(labels, dtype=torch.float, device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(ids, mask)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train = train_loss / len(train_loader)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_loader:\n",
        "            ids, mask = model.tokenize(list(texts))\n",
        "            ids, mask = ids.to(device), mask.to(device)\n",
        "            labels = torch.tensor(labels, dtype=torch.float, device=device)\n",
        "\n",
        "            logits = model(ids, mask)\n",
        "            val_loss += criterion(logits, labels).item()\n",
        "\n",
        "    avg_val = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch} — Train: {avg_train:.4f} — Val: {avg_val:.4f}\")\n",
        "\n",
        "    if avg_val < best_val:\n",
        "        best_val = avg_val\n",
        "        stalled = 0\n",
        "    else:\n",
        "        stalled += 1\n",
        "        if stalled >= patience:\n",
        "            print(f\"Early stop at epoch {epoch}\")\n",
        "            break"
      ],
      "metadata": {
        "id": "UZtmUExtXw8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb46efd-6ecc-46b3-ad22-cdbb1117d51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_36092/2428241220.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels, dtype=torch.float, device=device)\n",
            "/tmp/ipykernel_36092/2428241220.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels, dtype=torch.float, device=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 — Train: 0.7407 — Val: 0.6501\n",
            "Epoch 2 — Train: 0.5302 — Val: 0.3672\n",
            "Epoch 3 — Train: 0.3169 — Val: 0.2722\n",
            "Epoch 4 — Train: 0.2538 — Val: 0.2450\n",
            "Epoch 5 — Train: 0.2215 — Val: 0.2186\n",
            "Epoch 6 — Train: 0.1983 — Val: 0.2098\n",
            "Epoch 7 — Train: 0.1875 — Val: 0.2233\n",
            "Epoch 8 — Train: 0.1711 — Val: 0.1894\n",
            "Epoch 9 — Train: 0.1655 — Val: 0.2014\n",
            "Epoch 10 — Train: 0.1518 — Val: 0.1855\n",
            "Epoch 11 — Train: 0.1418 — Val: 0.1844\n",
            "Epoch 12 — Train: 0.1355 — Val: 0.2220\n",
            "Epoch 13 — Train: 0.1314 — Val: 0.2060\n",
            "Epoch 14 — Train: 0.1270 — Val: 0.2241\n",
            "Epoch 15 — Train: 0.1193 — Val: 0.2015\n",
            "Epoch 16 — Train: 0.1143 — Val: 0.1997\n",
            "Early stop at epoch 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation Metrics"
      ],
      "metadata": {
        "id": "-UkklgdFX0df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Evaluation =====\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for texts, labels in test_loader:\n",
        "        ids, mask = model.tokenize(list(texts))\n",
        "        ids, mask = ids.to(device), mask.to(device)\n",
        "        logits = model(ids, mask)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).long().cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "print(\"Test Accuracy:\", acc)\n",
        "print(\"Precision:\", p, \"Recall:\", r, \"F1:\", f1)"
      ],
      "metadata": {
        "id": "LXEmjzPIX2Er",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e3f9fe-be59-4330-ffa5-200eb0b94d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9322152341020266\n",
            "Precision: 0.9329418889862621 Recall: 0.9322152341020266 F1: 0.9321087882279159\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}